{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import rare_traffic_sign_solution as rtss\n",
    "import lib\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from math import floor, ceil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import json\n",
    "import shutil\n",
    "import requests\n",
    "import functools\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (20, 1)\n",
    "\n",
    "MEAN = np.array([0.485, 0.456, 0.406])\n",
    "STD = np.array([0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rtss.ModelWithHead()\n",
    "model.load_nn('improved_features_model.pth')\n",
    "model.load_head('knn_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = rtss.TestData('smalltest', 'classes.json', 'smalltest_annotations.csv', return_class_name=False)\n",
    "knn_test = DataLoader(dataset_test, batch_size=16, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7394)\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "for batch in knn_test:\n",
    "    images, _, labels = batch\n",
    "    images.to(device)\n",
    "    preds = model.predict(images)\n",
    "    acc += (torch.Tensor(preds) == labels).type(torch.float).mean()\n",
    "acc /= len(knn_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7394)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "869e465c4f25397806eb98effb5307a5d5d93b3ae0a2a52b8d6469552bf70b42"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
